# -*- coding: utf-8 -*-
"""project-pertama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16q1kkIdNZk5QNiNOM1CZq4QMEtryDVRv

# Phone addiction

## import and load dataset
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import  OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import AdaBoostRegressor
from sklearn.linear_model import LinearRegression

addict = pd.read_csv('/content/Students Social Media Addiction.csv')
addict

"""Dataset memiliki 13 kolom dan 705 baris

## EDA
"""

addict.info()

addict.describe()

"""- Dataset berisi 705
- Kolom `Avg_Daily_Usage_Hours` adalah target utama dan memiliki nilai antara 1.5 hingga 8.5.

### Penanganan Outliers
"""

numerical_features = ['Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Mental_Health_Score', 'Addicted_Score']

for feature in numerical_features:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=addict[feature])
    plt.title(f'Box Plot of Avg_Daily_Usage_Hours')
    plt.xlabel(feature)
    plt.show()

filtered_data = addict[(addict["Avg_Daily_Usage_Hours"] == 1.5) | (addict["Avg_Daily_Usage_Hours"] == 8.5)]
filtered_data

"""Karna data di atas tidak representatif atau mewakili sebagian data, maka kedua data tersebut bisa dianggap kategori khusus dan perlu di hapus."""

numeric_cols = addict.select_dtypes(include='number').columns

Q1 = addict[numeric_cols].quantile(0.25)
Q3 = addict[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

filter_outliers = ~((addict[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (addict[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)

addict = addict[filter_outliers]

addict.shape

"""jumlah baris data yang dihapus yakni 3 total data sebelum di hapus 705 ==> 702"""

plt.figure(figsize=(10, 6))
sns.boxplot(x=addict['Avg_Daily_Usage_Hours'])
plt.title(f'Box Plot of Avg_Daily_Usage_Hours')
plt.xlabel(feature)
plt.show()

"""data sudah bersih

### Univariate EDA
"""

addict.info()

numerical_features = ['Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Mental_Health_Score', 'Conflicts_Over_Social_Media', 'Addicted_Score']
categorical_features = ['Gender', 'Academic_Level', 'Country', 'Most_Used_Platform', 'Affects_Academic_Performance', 'Relationship_Status' ]

"""#### cat_feat"""

feature = categorical_features[0]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel ':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='pie', title=feature, startangle=90, autopct='%1.1f%%', labels=None);
plt.ylabel("")
plt.legend(loc='upper right', labels=count.index)

"""Jumlah sample gender di dalam dataset seimbang"""

feature = categorical_features[1]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel ':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Sample didominasi oleh Mahasiswa Aktif dengan total 351 diikuti oleh Graduate yang berjumlah 324 dan High School student berjumlah 27"""

feature = categorical_features[2]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
plt.figure(figsize=(27, 15))
count.plot(kind='pie', title=feature, autopct='%1.1f%%', labels=None);
plt.ylabel("")
plt.legend(loc='best', labels=count.index)

"""Data menunjukkan bahwa sebagian besar negara memiliki jumlah Sample atau kejadian yang sangat rendah, sementara beberapa negara memiliki jumlah yang jauh lebih tinggi."""

feature = categorical_features[3]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan diagram tersebut, Instagram adalah aplikasi yang paling populer di kalangan pengguna (dengan jumlah pengguna terbanyak, bukan durasi penggunaan terlama)."""

feature = categorical_features[4]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari total 451 siswa/mahasiswa dalam dataset, penggunaan ponsel memiliki pengaruh yang signifikan terhadap Kinerja Akademik (Academic Performance)."""

feature = categorical_features[5]
count = addict[feature].value_counts()
percent = 100*addict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Status hubungan juga berperan dalam durasi penggunaan ponsel yang lama, terutama untuk aktivitas seperti berkirim pesan, panggilan video, dan telepon. Data menunjukkan distribusi status hubungan dalam sampel adalah: 54.6% single, 40.9% sedang menjalin hubungan (in relationship), dan 4.6% memiliki status yang rumit (complicated).

#### numerical_feat
"""

addict.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari histogram `Addicted_Score`, kita bisa memperoleh beberapa informasi, antara lain:
- Distribusi menunjukkan puncak pada skor 7, mengindikasikan bahwa skor kecanduan yang paling umum di antara siswa adalah 7.
- Skor 5 dan 8 juga memiliki frekuensi yang cukup tinggi, menunjukkan sejumlah besar siswa dengan tingkat kecanduan sedang hingga tinggi.
- Rentang skor kecanduan dalam dataset ini adalah dari 3 hingga 9.
- Frekuensi cenderung lebih rendah pada skor ekstrem (3 dan 9), menunjukkan bahwa hanya sebagian kecil siswa yang memiliki tingkat kecanduan yang sangat rendah atau sangat tinggi berdasarkan skala ini.
- Distribusi tidak terlalu miring; terdapat beberapa puncak yang menunjukkan pengelompokan skor kecanduan pada nilai-nilai tertentu.

### Multivariate EDA

#### cat_feat
"""

cat_features = addict.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="Addicted_Score", kind="bar", dodge=False, height = 4, aspect = 3,  data=addict, palette="Set3")
  plt.title("Rata-rata 'Addicted_Score' Relatif terhadap - {}".format(col))

"""- Rata-rata skor kecanduan antara siswa berjenis kelamin Perempuan (Female) dan Laki-laki (Male) terlihat cukup mirip. Meskipun terdapat sedikit perbedaan pada nilai rata-rata dan error bar, perbedaan ini tidak tampak signifikan secara visual. Ini mengindikasikan bahwa gender mungkin bukan pembeda utama dalam tingkat kecanduan media sosial.
- Terdapat variasi rata-rata skor kecanduan di antara berbagai tingkat pendidikan. Siswa dengan tingkat pendidikan Sekolah Menengah Atas (High School) menunjukkan rata-rata skor kecanduan yang paling tinggi, diikuti oleh mahasiswa (Undergraduate). Siswa lulusan (Graduate) memiliki rata-rata skor kecanduan yang tampak paling rendah. Tingkat pendidikan sepertinya memiliki pengaruh terhadap tingkat kecanduan media sosial.
- Rata-rata skor kecanduan bervariasi secara signifikan di antara platform media sosial yang paling sering digunakan. Snapchat dan TikTok terlihat memiliki rata-rata skor kecanduan yang lebih tinggi dibandingkan platform lain. LINE menunjukkan rata-rata skor kecanduan yang paling rendah. Platform yang paling sering digunakan tampaknya sangat berkaitan dengan tingkat kecanduan media sosial.
- Siswa yang merasa bahwa penggunaan media sosial mempengaruhi (Yes) kinerja akademik mereka cenderung memiliki rata-rata skor kecanduan yang lebih tinggi dibandingkan dengan mereka yang merasa tidak (No) terpengaruh. Ini mengindikasikan adanya hubungan antara persepsi dampak negatif pada akademik dan tingkat kecanduan media sosial.
- Terdapat perbedaan dalam rata-rata skor kecanduan di antara status hubungan yang berbeda (In Relationship, Single, Complicated). Siswa dengan status Complicated dan Single menunjukkan rata-rata skor kecanduan yang sedikit lebih tinggi dibandingkan dengan mereka yang In Relationship. Status hubungan mungkin memiliki pengaruh terhadap tingkat kecanduan media sosial.

#### numerical_feat
"""

sns.pairplot(addict, diag_kind = 'kde')

"""Berdasarkan visualisasi pairplot, teridentifikasi beberapa potensi hubungan antar variabel. Terdapat indikasi korelasi positif antara rata-rata jam penggunaan media sosial harian (Avg_Daily_Usage_Hours) dengan skor kecanduan (Addicted_Score), menyiratkan bahwa semakin lama waktu yang dihabiskan di media sosial, semakin tinggi pula kemungkinan skor kecanduannya. Sebaliknya, jam tidur per malam (Sleep_Hours_Per_Night) cenderung berkorelasi negatif dengan durasi penggunaan media sosial dan skor kecanduan, di mana penggunaan yang lebih tinggi diasosiasikan dengan waktu tidur yang lebih sedikit. Skor kesehatan mental (Mental_Health_Score) juga menunjukkan kemungkinan hubungan negatif dengan intensitas penggunaan media sosial dan skor kecanduan, mengisyaratkan bahwa kesehatan mental yang kurang baik mungkin terkait dengan penggunaan media sosial yang lebih sering. Sementara itu, usia (Age) dan ID siswa (Student_ID) tidak menunjukkan pola korelasi linear yang jelas dengan variabel-variabel lainnya. Untuk mengukur kekuatan korelasi ini secara lebih tepat, analisis statistik kuantitatif seperti perhitungan koefisien korelasi diperlukan."""

plt.figure(figsize=(10, 8))
correlation_matrix = addict[numerical_features].corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""- Avg_Daily_Usage_Hours memiliki korelasi positif yang sangat kuat dengan Conflicts_Over_Social_Media (0.8) dan Addicted_Score (0.83). Ini menunjukkan bahwa semakin tinggi rata-rata jam penggunaan media sosial harian, semakin besar kemungkinan terjadinya konflik akibat media sosial dan semakin tinggi pula skor kecanduannya.
- Sleep_Hours_Per_Night memiliki korelasi negatif yang kuat dengan Avg_Daily_Usage_Hours (-0.79), Mental_Health_Score (-0.8), Conflicts_Over_Social_Media (-0.68), dan Addicted_Score (-0.76). Ini mengindikasikan bahwa semakin sedikit jam tidur per malam, cenderung semakin tinggi penggunaan media sosial, semakin rendah skor kesehatan mental, semakin sering terjadi konflik akibat media sosial, dan semakin tinggi skor kecanduannya.
- Mental_Health_Score memiliki korelasi negatif yang kuat dengan Avg_Daily_Usage_Hours (-0.8), Sleep_Hours_Per_Night (0.71 - korelasi positif, kebalikannya dari poin sebelumnya), Conflicts_Over_Social_Media (-0.89), dan Addicted_Score (-0.94). Ini menunjukkan bahwa skor kesehatan mental yang lebih rendah sangat terkait dengan penggunaan media sosial yang lebih tinggi, jam tidur yang lebih sedikit, lebih seringnya konflik akibat media sosial, dan skor kecanduan yang lebih tinggi.
- Conflicts_Over_Social_Media memiliki korelasi positif yang sangat kuat dengan Avg_Daily_Usage_Hours (0.8) dan Addicted_Score (0.93). Ini menegaskan bahwa semakin sering terjadi konflik akibat media sosial, semakin tinggi pula penggunaan media sosial dan skor kecanduannya.
- Addicted_Score memiliki korelasi positif yang sangat kuat dengan Avg_Daily_Usage_Hours (0.83) dan Conflicts_Over_Social_Media (0.93). Ini menunjukkan bahwa skor kecanduan yang tinggi sangat erat kaitannya dengan durasi penggunaan media sosial yang lama dan seringnya konflik terkait media sosial.
- Age menunjukkan korelasi yang relatif lemah dengan semua fitur lainnya, dengan nilai korelasi yang mendekati nol.
"""

addict = pd.concat([addict, pd.get_dummies(addict['Gender'], prefix='Gender')], axis=1)
addict = pd.concat([addict, pd.get_dummies(addict['Academic_Level'], prefix='Academic_Level')], axis=1)
addict = pd.concat([addict, pd.get_dummies(addict['Most_Used_Platform'], prefix='Most_Used_Platform')], axis=1)
addict = pd.concat([addict, pd.get_dummies(addict['Relationship_Status'], prefix='Relationship_Status')], axis=1)
addict = pd.concat([addict, pd.get_dummies(addict['Affects_Academic_Performance'], prefix='Affects_Academic_Performance')], axis=1)

addict.drop(['Gender', 'Country', 'Academic_Level', 'Most_Used_Platform', 'Relationship_Status', 'Affects_Academic_Performance'], axis=1, inplace=True)

addict.head()

"""Country di drop karna kurang relevan dan jika dilakukan onehot encoding rasanya akan terlalu banyak column nantinya"""

addict.info()

"""## train-test-split"""

sns.pairplot(addict[['Mental_Health_Score', 'Addicted_Score', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Conflicts_Over_Social_Media']], plot_kws={"s": 10})
plt.suptitle("Pairplot Fitur-fitur Berpengaruh Terhadap Kesehatan Mental dan Kecanduan", y=1.02)
plt.show()

from sklearn.model_selection import train_test_split

X = addict.drop(["Addicted_Score"],axis =1)
y = addict["Addicted_Score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print(f'Total of sample in dataset: {len(addict)}')
print(f'Total of sample in whole dataset: {len(X)}')
print(f'Total of sample in train dataset: {len(X_train)}')
print(f'Total of sample in test dataset: {len(X_test)}')

"""## Standardization"""

numerical_features = ['Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Mental_Health_Score', 'Conflicts_Over_Social_Media']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""## Modeling"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RF', 'LR','Boosting'])

"""### KNN"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""### RF"""

# Definisikan parameter yang akan diuji (grid parameter) untuk Random Forest
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 16, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 3]
}

# Inisialisasi model Random Forest
rf = RandomForestRegressor(random_state=55, n_jobs=-1)

# Inisialisasi Grid Search
grid_search_rf = GridSearchCV(estimator=rf,
                           param_grid=param_grid_rf,
                           cv=3,  # Jumlah fold dalam cross-validation
                           scoring='neg_mean_squared_error', # Metrik evaluasi
                           n_jobs=-1) # Gunakan semua core CPU

# Lakukan Grid Search pada data training
grid_search_rf.fit(X_train, y_train)

# Parameter terbaik yang ditemukan oleh Grid Search
best_params_rf = grid_search_rf.best_params_
print(f"Parameter terbaik untuk Random Forest (Grid Search): {best_params_rf}")

# Model Random Forest terbaik hasil Grid Search
best_rf_model = grid_search_rf.best_estimator_

# Evaluasi model terbaik pada data training
train_mse_best_rf = mean_squared_error(y_pred=best_rf_model.predict(X_train), y_true=y_train)
print(f"Train MSE dengan Random Forest terbaik (Grid Search): {train_mse_best_rf}")

# Simpan hasil train_mse ke dalam DataFrame 'models'
models.loc['train_mse_gridsearch','RF'] = train_mse_best_rf

# Model Random Forest awal Anda (tanpa Grid Search)
RF_awal = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF_awal.fit(X_train, y_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF_awal.predict(X_train), y_true=y_train)

"""### LR"""

lr = LinearRegression()
lr.fit(X_train, y_train)

models.loc['train_mse','LR'] = mean_squared_error(y_pred=lr.predict(X_train), y_true=y_train)

"""### Boosting Algorithm"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## Evaluasi"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])
# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','LR', 'Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': best_rf_model, 'LR': lr, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""- Model Random Forest menunjukkan performa terbaik dengan nilai MSE test yang paling rendah. Namun, perlu diwaspadai potensi overfitting karena perbedaan yang signifikan antara MSE train dan test.
- Model Linear Regression dan Boosting juga menunjukkan performa yang baik dengan nilai MSE yang rendah dan tidak terlalu jauh berbeda antara data train dan test.
- Model KNN memiliki performa yang paling buruk di antara keempat model ini berdasarkan nilai MSE.
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Berdasarkan visualisasi dan contoh prediksi, Model Random Forest memberikan prediksi yang paling akurat, yaitu 7.0, yang sama persis dengan nilai sebenarnya (dibulatkan). Model Boosting juga memberikan prediksi yang cukup dekat, yaitu 7.1. Model Linear Regression memprediksi 6.7, yang juga relatif dekat. Dan Model KNN memberikan prediksi yang paling jauh dari nilai sebenarnya, yaitu 5.8."""